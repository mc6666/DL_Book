{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequential model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 建立模型結構"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型語法 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型語法 2：將input_shape拿掉，以model參數設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "x = tf.keras.layers.Input(shape=(28, 28))\n",
    "# 或 x = tf.Variable(tf.random.truncated_normal([28, 28]))\n",
    "y = model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型語法 3：可以直接串連神經層"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer1 = tf.keras.layers.Dense(2, activation=\"relu\", name=\"layer1\")\n",
    "layer2 = tf.keras.layers.Dense(3, activation=\"relu\", name=\"layer2\")\n",
    "layer3 = tf.keras.layers.Dense(4, name=\"layer3\")\n",
    "\n",
    "# Call layers on a test input\n",
    "x = tf.ones((3, 3))\n",
    "y = layer3(layer2(layer1(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 臨時加減神經層"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "神經層數: 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.layers.core.Flatten at 0x18336491910>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x18270b652e0>,\n",
       " <tensorflow.python.keras.layers.core.Dropout at 0x18276ff08b0>]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# 刪減一層\n",
    "model.pop()\n",
    "print(f'神經層數: {len(model.layers)}')\n",
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "神經層數: 4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.layers.core.Flatten at 0x18336491910>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x18270b652e0>,\n",
       " <tensorflow.python.keras.layers.core.Dropout at 0x18276ff08b0>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x18252b4cfd0>]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 增加一層\n",
    "model.add(tf.keras.layers.Dense(10))\n",
    "print(f'神經層數: {len(model.layers)}')\n",
    "model.layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 取得模型及神經層資訊"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "神經層參數類別總數: 6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'layer1/kernel:0' shape=(28, 2) dtype=float32, numpy=\n",
       " array([[-0.40281397,  0.2205016 ],\n",
       "        [-0.03376389,  0.15561956],\n",
       "        [ 0.4151038 ,  0.02849016],\n",
       "        [-0.15993604,  0.03800485],\n",
       "        [ 0.06474555,  0.39933097],\n",
       "        [ 0.41804487, -0.35671836],\n",
       "        [-0.09304568, -0.12987521],\n",
       "        [-0.07738718,  0.4214089 ],\n",
       "        [-0.03624141, -0.15986142],\n",
       "        [ 0.41953433, -0.14494684],\n",
       "        [-0.16713199, -0.36726573],\n",
       "        [ 0.28147936, -0.07306954],\n",
       "        [ 0.06702495,  0.29314017],\n",
       "        [-0.4076838 , -0.22369348],\n",
       "        [ 0.35500747, -0.20532322],\n",
       "        [-0.4465798 , -0.44517472],\n",
       "        [-0.03784758,  0.18521959],\n",
       "        [-0.32220033, -0.2665765 ],\n",
       "        [-0.02831304, -0.01577556],\n",
       "        [ 0.39644188, -0.16043621],\n",
       "        [ 0.32985735,  0.40040267],\n",
       "        [ 0.440423  , -0.3224007 ],\n",
       "        [ 0.08332956, -0.33867747],\n",
       "        [-0.14314255,  0.11406481],\n",
       "        [-0.4151996 ,  0.03236541],\n",
       "        [ 0.16692811,  0.4445855 ],\n",
       "        [-0.28081325, -0.15366495],\n",
       "        [-0.08408925, -0.07401264]], dtype=float32)>,\n",
       " <tf.Variable 'layer1/bias:0' shape=(2,) dtype=float32, numpy=array([0., 0.], dtype=float32)>,\n",
       " <tf.Variable 'layer2/kernel:0' shape=(2, 3) dtype=float32, numpy=\n",
       " array([[-0.85765153, -0.52234036,  0.6214608 ],\n",
       "        [ 0.39134014,  0.85754156, -0.3411767 ]], dtype=float32)>,\n",
       " <tf.Variable 'layer2/bias:0' shape=(3,) dtype=float32, numpy=array([0., 0., 0.], dtype=float32)>,\n",
       " <tf.Variable 'layer3/kernel:0' shape=(3, 4) dtype=float32, numpy=\n",
       " array([[ 0.69865596,  0.38489008, -0.72880864, -0.13361835],\n",
       "        [ 0.27738178, -0.41328734,  0.6602769 , -0.44029424],\n",
       "        [ 0.11844432,  0.45066047,  0.516515  , -0.5549101 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'layer3/bias:0' shape=(4,) dtype=float32, numpy=array([0., 0., 0., 0.], dtype=float32)>]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 建立 3 layers\n",
    "layer1 = tf.keras.layers.Dense(2, activation=\"relu\", name=\"layer1\", \n",
    "                               input_shape=(28, 28))\n",
    "layer2 = tf.keras.layers.Dense(3, activation=\"relu\", name=\"layer2\")\n",
    "layer3 = tf.keras.layers.Dense(4, name=\"layer3\")\n",
    "\n",
    "# 建立模型\n",
    "model = tf.keras.models.Sequential([\n",
    "  layer1,\n",
    "  layer2,\n",
    "  layer3\n",
    "])\n",
    "\n",
    "# 讀取模型權重\n",
    "print(f'神經層參數類別總數: {len(model.weights)}')\n",
    "model.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer2: [<tf.Variable 'layer2/kernel:0' shape=(2, 3) dtype=float32, numpy=\n",
      "array([[-0.85765153, -0.52234036,  0.6214608 ],\n",
      "       [ 0.39134014,  0.85754156, -0.3411767 ]], dtype=float32)>, <tf.Variable 'layer2/bias:0' shape=(3,) dtype=float32, numpy=array([0., 0., 0.], dtype=float32)>]\n"
     ]
    }
   ],
   "source": [
    "print(f'{layer2.name}: {layer2.weights}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_24\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "layer1 (Dense)               (None, 28, 2)             58        \n",
      "_________________________________________________________________\n",
      "layer2 (Dense)               (None, 28, 3)             9         \n",
      "_________________________________________________________________\n",
      "layer3 (Dense)               (None, 28, 4)             16        \n",
      "_________________________________________________________________\n",
      "layer4 (Dense)               (None, 28, 5)             25        \n",
      "=================================================================\n",
      "Total params: 108\n",
      "Trainable params: 108\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 取得模型彙總資訊\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 一邊加神經層，一邊顯示模型彙總資訊，以利除錯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_26\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 123, 123, 32)      2432      \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 121, 121, 32)      9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 40, 40, 32)        0         \n",
      "=================================================================\n",
      "Total params: 11,680\n",
      "Trainable params: 11,680\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_26\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 123, 123, 32)      2432      \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 121, 121, 32)      9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 40, 40, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 38, 38, 32)        9248      \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 36, 36, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 10, 10, 32)        9248      \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 8, 8, 32)          9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 32)          0         \n",
      "=================================================================\n",
      "Total params: 48,672\n",
      "Trainable params: 48,672\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.Input(shape=(250, 250, 3)))  # 250x250 RGB images\n",
    "model.add(layers.Conv2D(32, 5, strides=2, activation=\"relu\"))\n",
    "model.add(layers.Conv2D(32, 3, activation=\"relu\"))\n",
    "model.add(layers.MaxPooling2D(3))\n",
    "\n",
    "# 顯示目前模型彙總資訊\n",
    "model.summary()\n",
    "\n",
    "# The answer was: (40, 40, 32), so we can keep downsampling...\n",
    "\n",
    "model.add(layers.Conv2D(32, 3, activation=\"relu\"))\n",
    "model.add(layers.Conv2D(32, 3, activation=\"relu\"))\n",
    "model.add(layers.MaxPooling2D(3))\n",
    "model.add(layers.Conv2D(32, 3, activation=\"relu\"))\n",
    "model.add(layers.Conv2D(32, 3, activation=\"relu\"))\n",
    "model.add(layers.MaxPooling2D(2))\n",
    "\n",
    "# 顯示目前模型彙總資訊\n",
    "model.summary()\n",
    "\n",
    "# Now that we have 4x4 feature maps, time to apply global max pooling.\n",
    "model.add(layers.GlobalMaxPooling2D())\n",
    "\n",
    "# Finally, we add a classification layer.\n",
    "model.add(layers.Dense(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 取得每一層神經層的output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(1, 123, 123, 32), dtype=float32, numpy=\n",
       " array([[[[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]]]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 121, 121, 32), dtype=float32, numpy=\n",
       " array([[[[0.08905184, 0.        , 0.        , ..., 0.        ,\n",
       "           0.42522174, 0.        ],\n",
       "          [0.08905184, 0.        , 0.        , ..., 0.        ,\n",
       "           0.42522174, 0.        ],\n",
       "          [0.08905184, 0.        , 0.        , ..., 0.        ,\n",
       "           0.42522174, 0.        ],\n",
       "          ...,\n",
       "          [0.08905184, 0.        , 0.        , ..., 0.        ,\n",
       "           0.42522174, 0.        ],\n",
       "          [0.08905184, 0.        , 0.        , ..., 0.        ,\n",
       "           0.42522174, 0.        ],\n",
       "          [0.08905184, 0.        , 0.        , ..., 0.        ,\n",
       "           0.42522174, 0.        ]],\n",
       " \n",
       "         [[0.08905184, 0.        , 0.        , ..., 0.        ,\n",
       "           0.42522174, 0.        ],\n",
       "          [0.08905184, 0.        , 0.        , ..., 0.        ,\n",
       "           0.42522174, 0.        ],\n",
       "          [0.08905184, 0.        , 0.        , ..., 0.        ,\n",
       "           0.42522174, 0.        ],\n",
       "          ...,\n",
       "          [0.08905184, 0.        , 0.        , ..., 0.        ,\n",
       "           0.42522174, 0.        ],\n",
       "          [0.08905184, 0.        , 0.        , ..., 0.        ,\n",
       "           0.42522174, 0.        ],\n",
       "          [0.08905184, 0.        , 0.        , ..., 0.        ,\n",
       "           0.42522174, 0.        ]],\n",
       " \n",
       "         [[0.08905184, 0.        , 0.        , ..., 0.        ,\n",
       "           0.42522174, 0.        ],\n",
       "          [0.08905184, 0.        , 0.        , ..., 0.        ,\n",
       "           0.42522174, 0.        ],\n",
       "          [0.08905184, 0.        , 0.        , ..., 0.        ,\n",
       "           0.42522174, 0.        ],\n",
       "          ...,\n",
       "          [0.08905184, 0.        , 0.        , ..., 0.        ,\n",
       "           0.42522174, 0.        ],\n",
       "          [0.08905184, 0.        , 0.        , ..., 0.        ,\n",
       "           0.42522174, 0.        ],\n",
       "          [0.08905184, 0.        , 0.        , ..., 0.        ,\n",
       "           0.42522174, 0.        ]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.08905184, 0.        , 0.        , ..., 0.        ,\n",
       "           0.42522174, 0.        ],\n",
       "          [0.08905184, 0.        , 0.        , ..., 0.        ,\n",
       "           0.42522174, 0.        ],\n",
       "          [0.08905184, 0.        , 0.        , ..., 0.        ,\n",
       "           0.42522174, 0.        ],\n",
       "          ...,\n",
       "          [0.08905184, 0.        , 0.        , ..., 0.        ,\n",
       "           0.42522174, 0.        ],\n",
       "          [0.08905184, 0.        , 0.        , ..., 0.        ,\n",
       "           0.42522174, 0.        ],\n",
       "          [0.08905184, 0.        , 0.        , ..., 0.        ,\n",
       "           0.42522174, 0.        ]],\n",
       " \n",
       "         [[0.08905184, 0.        , 0.        , ..., 0.        ,\n",
       "           0.42522174, 0.        ],\n",
       "          [0.08905184, 0.        , 0.        , ..., 0.        ,\n",
       "           0.42522174, 0.        ],\n",
       "          [0.08905184, 0.        , 0.        , ..., 0.        ,\n",
       "           0.42522174, 0.        ],\n",
       "          ...,\n",
       "          [0.08905184, 0.        , 0.        , ..., 0.        ,\n",
       "           0.42522174, 0.        ],\n",
       "          [0.08905184, 0.        , 0.        , ..., 0.        ,\n",
       "           0.42522174, 0.        ],\n",
       "          [0.08905184, 0.        , 0.        , ..., 0.        ,\n",
       "           0.42522174, 0.        ]],\n",
       " \n",
       "         [[0.08905184, 0.        , 0.        , ..., 0.        ,\n",
       "           0.42522174, 0.        ],\n",
       "          [0.08905184, 0.        , 0.        , ..., 0.        ,\n",
       "           0.42522174, 0.        ],\n",
       "          [0.08905184, 0.        , 0.        , ..., 0.        ,\n",
       "           0.42522174, 0.        ],\n",
       "          ...,\n",
       "          [0.08905184, 0.        , 0.        , ..., 0.        ,\n",
       "           0.42522174, 0.        ],\n",
       "          [0.08905184, 0.        , 0.        , ..., 0.        ,\n",
       "           0.42522174, 0.        ],\n",
       "          [0.08905184, 0.        , 0.        , ..., 0.        ,\n",
       "           0.42522174, 0.        ]]]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 119, 119, 32), dtype=float32, numpy=\n",
       " array([[[[0.25353807, 0.        , 0.        , ..., 0.        ,\n",
       "           0.        , 0.05385849],\n",
       "          [0.25353807, 0.        , 0.        , ..., 0.        ,\n",
       "           0.        , 0.05385849],\n",
       "          [0.25353807, 0.        , 0.        , ..., 0.        ,\n",
       "           0.        , 0.05385849],\n",
       "          ...,\n",
       "          [0.25353807, 0.        , 0.        , ..., 0.        ,\n",
       "           0.        , 0.05385849],\n",
       "          [0.25353807, 0.        , 0.        , ..., 0.        ,\n",
       "           0.        , 0.05385849],\n",
       "          [0.25353807, 0.        , 0.        , ..., 0.        ,\n",
       "           0.        , 0.05385849]],\n",
       " \n",
       "         [[0.25353807, 0.        , 0.        , ..., 0.        ,\n",
       "           0.        , 0.05385849],\n",
       "          [0.25353807, 0.        , 0.        , ..., 0.        ,\n",
       "           0.        , 0.05385849],\n",
       "          [0.25353807, 0.        , 0.        , ..., 0.        ,\n",
       "           0.        , 0.05385849],\n",
       "          ...,\n",
       "          [0.25353807, 0.        , 0.        , ..., 0.        ,\n",
       "           0.        , 0.05385849],\n",
       "          [0.25353807, 0.        , 0.        , ..., 0.        ,\n",
       "           0.        , 0.05385849],\n",
       "          [0.25353807, 0.        , 0.        , ..., 0.        ,\n",
       "           0.        , 0.05385849]],\n",
       " \n",
       "         [[0.25353807, 0.        , 0.        , ..., 0.        ,\n",
       "           0.        , 0.05385849],\n",
       "          [0.25353807, 0.        , 0.        , ..., 0.        ,\n",
       "           0.        , 0.05385849],\n",
       "          [0.25353807, 0.        , 0.        , ..., 0.        ,\n",
       "           0.        , 0.05385849],\n",
       "          ...,\n",
       "          [0.25353807, 0.        , 0.        , ..., 0.        ,\n",
       "           0.        , 0.05385849],\n",
       "          [0.25353807, 0.        , 0.        , ..., 0.        ,\n",
       "           0.        , 0.05385849],\n",
       "          [0.25353807, 0.        , 0.        , ..., 0.        ,\n",
       "           0.        , 0.05385849]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.25353807, 0.        , 0.        , ..., 0.        ,\n",
       "           0.        , 0.05385849],\n",
       "          [0.25353807, 0.        , 0.        , ..., 0.        ,\n",
       "           0.        , 0.05385849],\n",
       "          [0.25353807, 0.        , 0.        , ..., 0.        ,\n",
       "           0.        , 0.05385849],\n",
       "          ...,\n",
       "          [0.25353807, 0.        , 0.        , ..., 0.        ,\n",
       "           0.        , 0.05385849],\n",
       "          [0.25353807, 0.        , 0.        , ..., 0.        ,\n",
       "           0.        , 0.05385849],\n",
       "          [0.25353807, 0.        , 0.        , ..., 0.        ,\n",
       "           0.        , 0.05385849]],\n",
       " \n",
       "         [[0.25353807, 0.        , 0.        , ..., 0.        ,\n",
       "           0.        , 0.05385849],\n",
       "          [0.25353807, 0.        , 0.        , ..., 0.        ,\n",
       "           0.        , 0.05385849],\n",
       "          [0.25353807, 0.        , 0.        , ..., 0.        ,\n",
       "           0.        , 0.05385849],\n",
       "          ...,\n",
       "          [0.25353807, 0.        , 0.        , ..., 0.        ,\n",
       "           0.        , 0.05385849],\n",
       "          [0.25353807, 0.        , 0.        , ..., 0.        ,\n",
       "           0.        , 0.05385849],\n",
       "          [0.25353807, 0.        , 0.        , ..., 0.        ,\n",
       "           0.        , 0.05385849]],\n",
       " \n",
       "         [[0.25353807, 0.        , 0.        , ..., 0.        ,\n",
       "           0.        , 0.05385849],\n",
       "          [0.25353807, 0.        , 0.        , ..., 0.        ,\n",
       "           0.        , 0.05385849],\n",
       "          [0.25353807, 0.        , 0.        , ..., 0.        ,\n",
       "           0.        , 0.05385849],\n",
       "          ...,\n",
       "          [0.25353807, 0.        , 0.        , ..., 0.        ,\n",
       "           0.        , 0.05385849],\n",
       "          [0.25353807, 0.        , 0.        , ..., 0.        ,\n",
       "           0.        , 0.05385849],\n",
       "          [0.25353807, 0.        , 0.        , ..., 0.        ,\n",
       "           0.        , 0.05385849]]]], dtype=float32)>]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 設定模型\n",
    "initial_model = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.Input(shape=(250, 250, 3)),\n",
    "        layers.Conv2D(32, 5, strides=2, activation=\"relu\"),\n",
    "        layers.Conv2D(32, 3, activation=\"relu\"),\n",
    "        layers.Conv2D(32, 3, activation=\"relu\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 設定模型的 input/output\n",
    "feature_extractor = tf.keras.Model(\n",
    "    inputs=initial_model.inputs,\n",
    "    outputs=[layer.output for layer in initial_model.layers],\n",
    ")\n",
    "\n",
    "# 呼叫 feature_extractor 取得 output\n",
    "x = tf.ones((1, 250, 250, 3))\n",
    "features = feature_extractor(x)\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 121, 121, 32), dtype=float32, numpy=\n",
       "array([[[[0.        , 0.41995677, 0.32568812, ..., 0.27618825,\n",
       "          0.        , 0.        ],\n",
       "         [0.        , 0.41995677, 0.32568812, ..., 0.27618825,\n",
       "          0.        , 0.        ],\n",
       "         [0.        , 0.41995677, 0.32568812, ..., 0.27618825,\n",
       "          0.        , 0.        ],\n",
       "         ...,\n",
       "         [0.        , 0.41995677, 0.32568812, ..., 0.27618825,\n",
       "          0.        , 0.        ],\n",
       "         [0.        , 0.41995677, 0.32568812, ..., 0.27618825,\n",
       "          0.        , 0.        ],\n",
       "         [0.        , 0.41995677, 0.32568812, ..., 0.27618825,\n",
       "          0.        , 0.        ]],\n",
       "\n",
       "        [[0.        , 0.41995677, 0.32568812, ..., 0.27618825,\n",
       "          0.        , 0.        ],\n",
       "         [0.        , 0.41995677, 0.32568812, ..., 0.27618825,\n",
       "          0.        , 0.        ],\n",
       "         [0.        , 0.41995677, 0.32568812, ..., 0.27618825,\n",
       "          0.        , 0.        ],\n",
       "         ...,\n",
       "         [0.        , 0.41995677, 0.32568812, ..., 0.27618825,\n",
       "          0.        , 0.        ],\n",
       "         [0.        , 0.41995677, 0.32568812, ..., 0.27618825,\n",
       "          0.        , 0.        ],\n",
       "         [0.        , 0.41995677, 0.32568812, ..., 0.27618825,\n",
       "          0.        , 0.        ]],\n",
       "\n",
       "        [[0.        , 0.41995677, 0.32568812, ..., 0.27618825,\n",
       "          0.        , 0.        ],\n",
       "         [0.        , 0.41995677, 0.32568812, ..., 0.27618825,\n",
       "          0.        , 0.        ],\n",
       "         [0.        , 0.41995677, 0.32568812, ..., 0.27618825,\n",
       "          0.        , 0.        ],\n",
       "         ...,\n",
       "         [0.        , 0.41995677, 0.32568812, ..., 0.27618825,\n",
       "          0.        , 0.        ],\n",
       "         [0.        , 0.41995677, 0.32568812, ..., 0.27618825,\n",
       "          0.        , 0.        ],\n",
       "         [0.        , 0.41995677, 0.32568812, ..., 0.27618825,\n",
       "          0.        , 0.        ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.        , 0.41995677, 0.32568812, ..., 0.27618825,\n",
       "          0.        , 0.        ],\n",
       "         [0.        , 0.41995677, 0.32568812, ..., 0.27618825,\n",
       "          0.        , 0.        ],\n",
       "         [0.        , 0.41995677, 0.32568812, ..., 0.27618825,\n",
       "          0.        , 0.        ],\n",
       "         ...,\n",
       "         [0.        , 0.41995677, 0.32568812, ..., 0.27618825,\n",
       "          0.        , 0.        ],\n",
       "         [0.        , 0.41995677, 0.32568812, ..., 0.27618825,\n",
       "          0.        , 0.        ],\n",
       "         [0.        , 0.41995677, 0.32568812, ..., 0.27618825,\n",
       "          0.        , 0.        ]],\n",
       "\n",
       "        [[0.        , 0.41995677, 0.32568812, ..., 0.27618825,\n",
       "          0.        , 0.        ],\n",
       "         [0.        , 0.41995677, 0.32568812, ..., 0.27618825,\n",
       "          0.        , 0.        ],\n",
       "         [0.        , 0.41995677, 0.32568812, ..., 0.27618825,\n",
       "          0.        , 0.        ],\n",
       "         ...,\n",
       "         [0.        , 0.41995677, 0.32568812, ..., 0.27618825,\n",
       "          0.        , 0.        ],\n",
       "         [0.        , 0.41995677, 0.32568812, ..., 0.27618825,\n",
       "          0.        , 0.        ],\n",
       "         [0.        , 0.41995677, 0.32568812, ..., 0.27618825,\n",
       "          0.        , 0.        ]],\n",
       "\n",
       "        [[0.        , 0.41995677, 0.32568812, ..., 0.27618825,\n",
       "          0.        , 0.        ],\n",
       "         [0.        , 0.41995677, 0.32568812, ..., 0.27618825,\n",
       "          0.        , 0.        ],\n",
       "         [0.        , 0.41995677, 0.32568812, ..., 0.27618825,\n",
       "          0.        , 0.        ],\n",
       "         ...,\n",
       "         [0.        , 0.41995677, 0.32568812, ..., 0.27618825,\n",
       "          0.        , 0.        ],\n",
       "         [0.        , 0.41995677, 0.32568812, ..., 0.27618825,\n",
       "          0.        , 0.        ],\n",
       "         [0.        , 0.41995677, 0.32568812, ..., 0.27618825,\n",
       "          0.        , 0.        ]]]], dtype=float32)>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 設定模型\n",
    "initial_model = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.Input(shape=(250, 250, 3)),\n",
    "        layers.Conv2D(32, 5, strides=2, activation=\"relu\"),\n",
    "        layers.Conv2D(32, 3, activation=\"relu\", name=\"my_intermediate_layer\"),\n",
    "        layers.Conv2D(32, 3, activation=\"relu\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 設定模型的 input/output\n",
    "feature_extractor = tf.keras.Model(\n",
    "    inputs=initial_model.inputs,\n",
    "    outputs=initial_model.get_layer(name=\"my_intermediate_layer\").output,\n",
    ")\n",
    "\n",
    "# 呼叫 feature_extractor 取得 output\n",
    "x = tf.ones((1, 250, 250, 3))\n",
    "features = feature_extractor(x)\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
