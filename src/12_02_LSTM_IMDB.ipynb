{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cWqzh03Zari4"
   },
   "source": [
    "# 影評資料集(IMDB movie review)情緒分析 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "executionInfo": {
     "elapsed": 1544,
     "status": "ok",
     "timestamp": 1629007586819,
     "user": {
      "displayName": "Chen Michael",
      "photoUrl": "",
      "userId": "15304487147302560206"
     },
     "user_tz": -480
    },
    "id": "b8vEtVKBari7"
   },
   "outputs": [],
   "source": [
    "# 載入相關套件\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.layers import Embedding, Dense, LSTM\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "executionInfo": {
     "elapsed": 267,
     "status": "ok",
     "timestamp": 1629007735948,
     "user": {
      "displayName": "Chen Michael",
      "photoUrl": "",
      "userId": "15304487147302560206"
     },
     "user_tz": -480
    },
    "id": "WsJ6HOaSari8"
   },
   "outputs": [],
   "source": [
    "# 參數設定\n",
    "batch_size = 128            # 批量\n",
    "embedding_output_dims = 15  # 嵌入層輸出維度\n",
    "max_sequence_length = 300   # 句子最大字數\n",
    "num_distinct_words = 5000   # 字典\n",
    "number_of_epochs = 5        # 訓練執行週期\n",
    "validation_split = 0.20     # 驗證資料比例\n",
    "verbosity_mode = 1          # 訓練資料訊息顯示程度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8121,
     "status": "ok",
     "timestamp": 1629008160604,
     "user": {
      "displayName": "Chen Michael",
      "photoUrl": "",
      "userId": "15304487147302560206"
     },
     "user_tz": -480
    },
    "id": "zsLrA-Sqari9",
    "outputId": "d9aca530-fe6c-494a-aee0-97192a19d70a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<__array_function__ internals>:5: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "C:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\datasets\\imdb.py:155: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
      "C:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\datasets\\imdb.py:156: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000,)\n",
      "(25000,)\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 300, 15)           75000     \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 10)                1040      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 76,051\n",
      "Trainable params: 76,051\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 載入 IMDB 影評資料集，TensorFlow 已將資料轉為索引值\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(\n",
    "    num_words=num_distinct_words)\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "\n",
    "# 長度不足時補 0\n",
    "padded_inputs = pad_sequences(x_train, maxlen=max_sequence_length\n",
    "                              , value = 0.0) \n",
    "padded_inputs_test = pad_sequences(x_test, maxlen=max_sequence_length\n",
    "                                   , value = 0.0) \n",
    "\n",
    "# 建立模型\n",
    "model = Sequential()\n",
    "model.add(Embedding(num_distinct_words, embedding_output_dims, \n",
    "                    input_length=max_sequence_length))\n",
    "model.add(LSTM(10))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# 指定優化器、損失函數\n",
    "model.compile(optimizer=Adam(), loss=\"binary_crossentropy\", metrics=['accuracy'])\n",
    "\n",
    "# 模型彙總資訊\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 268,
     "status": "ok",
     "timestamp": 1629007862272,
     "user": {
      "displayName": "Chen Michael",
      "photoUrl": "",
      "userId": "15304487147302560206"
     },
     "user_tz": -480
    },
    "id": "kb2xyEpSari-",
    "outputId": "1ef2d7b4-cdc1-4d70-e518-123124b9a6e5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24884,
     "status": "ok",
     "timestamp": 1629008193359,
     "user": {
      "displayName": "Chen Michael",
      "photoUrl": "",
      "userId": "15304487147302560206"
     },
     "user_tz": -480
    },
    "id": "AeAR2nMNari_",
    "outputId": "194f2323-4523-4021-d6a4-814d241e2138"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "157/157 [==============================] - 5s 21ms/step - loss: 0.5697 - accuracy: 0.7356 - val_loss: 0.4291 - val_accuracy: 0.8240\n",
      "Epoch 2/5\n",
      "157/157 [==============================] - 3s 19ms/step - loss: 0.3298 - accuracy: 0.8767 - val_loss: 0.3258 - val_accuracy: 0.8672\n",
      "Epoch 3/5\n",
      "157/157 [==============================] - 3s 19ms/step - loss: 0.2546 - accuracy: 0.9084 - val_loss: 0.2973 - val_accuracy: 0.8758\n",
      "Epoch 4/5\n",
      "157/157 [==============================] - 3s 19ms/step - loss: 0.2152 - accuracy: 0.9242 - val_loss: 0.3068 - val_accuracy: 0.8744\n",
      "Epoch 5/5\n",
      "157/157 [==============================] - 3s 19ms/step - loss: 0.1940 - accuracy: 0.9352 - val_loss: 0.3234 - val_accuracy: 0.8728\n",
      "Loss: 0.3329777419567108, Accuracy: 87.00399994850159%\n"
     ]
    }
   ],
   "source": [
    "# 訓練模型\n",
    "history = model.fit(padded_inputs, y_train, batch_size=batch_size, \n",
    "            epochs=number_of_epochs, verbose=verbosity_mode, \n",
    "            validation_split=validation_split)\n",
    "\n",
    "# 模型評估\n",
    "test_results = model.evaluate(padded_inputs_test, y_test, verbose=False)\n",
    "print(f'Loss: {test_results[0]}, Accuracy: {100*test_results[1]}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "j7JTjqPJari_"
   },
   "outputs": [],
   "source": [
    "# 模型存檔\n",
    "model.save('LSTM_IMDB.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 669,
     "status": "ok",
     "timestamp": 1629008210696,
     "user": {
      "displayName": "Chen Michael",
      "photoUrl": "",
      "userId": "15304487147302560206"
     },
     "user_tz": -480
    },
    "id": "SUMhFTcHarjA",
    "outputId": "5532abbb-ccf9-4180-f243-1559154898be"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fawn',\n",
       " 'tsukino',\n",
       " 'nunnery',\n",
       " 'sonja',\n",
       " 'vani',\n",
       " 'woods',\n",
       " 'spiders',\n",
       " 'hanging',\n",
       " 'woody',\n",
       " 'trawling']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 取得字詞與索引的對照表字典\n",
    "imdb_dict = imdb.get_word_index()\n",
    "list(imdb_dict.keys())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "executionInfo": {
     "elapsed": 325,
     "status": "ok",
     "timestamp": 1629008247865,
     "user": {
      "displayName": "Chen Michael",
      "photoUrl": "",
      "userId": "15304487147302560206"
     },
     "user_tz": -480
    },
    "id": "zHGTSMiJarjB"
   },
   "outputs": [],
   "source": [
    "# 反轉字典，變成索引與字詞的對照表\n",
    "imdb_dict_reversed = {}\n",
    "for k, v in imdb_dict.items():\n",
    "    imdb_dict_reversed[v] = k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "executionInfo": {
     "elapsed": 346,
     "status": "ok",
     "timestamp": 1629008658442,
     "user": {
      "displayName": "Chen Michael",
      "photoUrl": "",
      "userId": "15304487147302560206"
     },
     "user_tz": -480
    },
    "id": "x-qdr0-VarjC",
    "outputId": "6c890b4e-e221-49c8-97f7-fe0f8ac08961",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the wonder own as by is sequence i i and and to of hollywood br of down and getting boring of ever it sadly sadly sadly i i was then does don't close and after one carry as by are be and all family turn in does as three part in another some to be probably with world and her an have and beginning own as is sequence \n",
      "\n",
      "\n",
      "the as you world's is quite br and most that quest are chase to being quickly of little it time hell to plot br of something long put are of every place this and and of and storytelling being nasty not of you warren in is failed club i i of films pay so sequences and film okay uses to received and if time done for room and viewer as cartoon of gives to forgettable br be because many these of and and contained gives it wreck scene to more was two when had find as you another it of themselves probably who and storytelling if itself by br about 1950's films not would effects that her box to miike for if hero close seek end is very together movie of and got say kong and fred close bore there is playing lot of and pan place trilogy of lacks br of their time much this men as on it is telling program br and okay and to frustration at corner and she of sequences to political clearly in of drugs keep guy i i was throwing room and as it by br be plot many for occasionally film and boyfriend difficult kid as you it failed not if gerard to if woman in and is police fi spooky or of self what have pretty in can so suit you good 2 which why super as it main of my i i  if time screenplay in same this remember and have action one in realistic that better of lessons \n"
     ]
    }
   ],
   "source": [
    "# 顯示測試資料前兩筆為文字\n",
    "text = []\n",
    "for i, line in enumerate(padded_inputs_test[:2]):\n",
    "    text.append('')\n",
    "    for j, word in enumerate(line):\n",
    "        if word != 0:\n",
    "            text[i] += imdb_dict_reversed[word]+' '\n",
    "\n",
    "print('\\n\\n\\n'.join(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 260,
     "status": "ok",
     "timestamp": 1629008494278,
     "user": {
      "displayName": "Chen Michael",
      "photoUrl": "",
      "userId": "15304487147302560206"
     },
     "user_tz": -480
    },
    "id": "IQlQE0k5arjD",
    "outputId": "fe5a019a-3bd0-4976-fd3e-71f39491609f",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'close'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_dict_reversed[488]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "488"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_dict['close']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "ZOip6zMoarjD"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "# 以上述語句測試\n",
    "X_tokens = []\n",
    "for line in text:\n",
    "    tokens = nltk.word_tokenize(line)\n",
    "    tokens = [token.strip() for token in tokens]\n",
    "    X_tokens.append(tokens)\n",
    "    \n",
    "# 轉為索引值\n",
    "import numpy as np\n",
    "X_index = np.zeros((len(text), max_sequence_length))\n",
    "for i, line in enumerate(X_tokens):\n",
    "    for j, word in enumerate(line):\n",
    "        if j >= max_sequence_length:\n",
    "            break\n",
    "        if word in imdb_dict:\n",
    "            # 因為num_distinct_words=5000, 怕反轉為數字時會出錯，超過5000時設為0\n",
    "            if imdb_dict[word] < num_distinct_words:\n",
    "                X_index[i, j] = imdb_dict[word]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   1,  591,  202,   14,   31,    6,  717,   10,   10,    2,    2,\n",
       "          5,    4,  360,    7,    4,  177,    2,  394,  354,    4,  123,\n",
       "          9, 1035, 1035, 1035,   10,   10,   13,   92,  124,   78,    0,\n",
       "        488,    2,  100,   28, 1668,   14,   31,   23,   27,    2,   29,\n",
       "        220,  468,    8,  124,   14,  286,  170,    8,  157,   46,    5,\n",
       "         27,  239,   16,  179,    2,   38,   32,   25,    2,  451])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_index[0, :65].astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "7xFV6mHParjE",
    "outputId": "5297bb4c-43b4-4f5d-c922-99eb4ad8eb6a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:455: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 長度不足時補 0\n",
    "padded_inputs = pad_sequences(X_index, maxlen=max_sequence_length, \n",
    "                      value = 0.0) \n",
    "\n",
    "# 預測\n",
    "np.argmax(model.predict(padded_inputs), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 685,
     "status": "ok",
     "timestamp": 1629008521456,
     "user": {
      "displayName": "Chen Michael",
      "photoUrl": "",
      "userId": "15304487147302560206"
     },
     "user_tz": -480
    },
    "id": "wqRRWO3BarjE",
    "outputId": "13ac0e0b-0f76-4c3c-fa76-0d43188ce80d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 以原資料預測，確認答案相同\n",
    "np.argmax(model.predict(padded_inputs_test[:2]), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XGKJkjikarjF"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "12_02_LSTM_IMDB.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
