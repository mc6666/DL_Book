{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 簡單的RNN實作"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 程式參考來源：\n",
    "- https://keras.io/api/layers/core_layers/embedding/\n",
    "- https://machinelearningmastery.com/use-word-embedding-layers-deep-learning-keras/\n",
    "- https://keras.io/guides/working_with_rnns/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 載入相關套件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 載入相關套件\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 嵌入層測試"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 10, 64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-4.09067757e-02,  4.13169377e-02,  3.79419327e-03,\n",
       "        -8.12249258e-03,  3.98785211e-02,  4.84695174e-02,\n",
       "        -3.52774151e-02, -2.07844265e-02, -3.32484469e-02,\n",
       "         1.15686059e-02, -2.05504298e-02,  4.01307456e-02,\n",
       "        -3.33517343e-02,  4.53372933e-02, -1.14959478e-02,\n",
       "        -3.42349410e-02, -2.31464747e-02,  4.93111499e-02,\n",
       "         3.65070440e-02,  1.29793398e-02,  3.98182534e-02,\n",
       "        -4.83712554e-02,  2.58997716e-02,  3.76032479e-02,\n",
       "         4.48194407e-02, -3.18442471e-02,  1.50911510e-05,\n",
       "         4.13540117e-02, -1.83008537e-02, -3.48059647e-02,\n",
       "         4.89773043e-02, -2.05516815e-04,  6.68109581e-03,\n",
       "         2.11245939e-03, -4.50933240e-02,  7.08359480e-03,\n",
       "        -3.61134633e-02, -3.95359285e-02,  4.99451868e-02,\n",
       "         4.33850288e-03, -2.35689413e-02,  4.22668122e-02,\n",
       "         2.27580108e-02,  2.43217610e-02, -3.27639952e-02,\n",
       "        -3.15042622e-02, -2.30477341e-02,  3.61427777e-02,\n",
       "        -4.26368602e-02, -4.84775379e-03, -3.10918931e-02,\n",
       "         7.88927078e-04,  1.85660757e-02,  1.30038597e-02,\n",
       "        -3.33666429e-02,  4.58572842e-02,  2.17584409e-02,\n",
       "         7.53457472e-03,  3.69536988e-02,  1.99151523e-02,\n",
       "        -3.95703912e-02,  1.10901594e-02, -2.64303926e-02,\n",
       "         4.55486886e-02],\n",
       "       [ 1.27134062e-02, -1.97860952e-02,  4.94781621e-02,\n",
       "         1.00211501e-02,  2.67091058e-02, -1.38590336e-02,\n",
       "         1.51549093e-02, -2.29849704e-02, -3.07157878e-02,\n",
       "         4.09653895e-02, -2.45942604e-02,  2.37767957e-02,\n",
       "         2.17179321e-02,  2.72304751e-02, -3.64836343e-02,\n",
       "         1.04530565e-02, -4.95854616e-02,  7.19127804e-03,\n",
       "        -2.19663866e-02,  4.11140956e-02, -2.70841960e-02,\n",
       "        -3.14197689e-03, -1.67963877e-02,  9.25515965e-03,\n",
       "         2.01185830e-02, -4.51982506e-02,  8.03029537e-03,\n",
       "         2.23300718e-02,  1.24705918e-02, -2.87782550e-02,\n",
       "         4.71124537e-02,  2.14352123e-02,  1.00642927e-02,\n",
       "         2.72439755e-02,  4.80915420e-02, -4.25335020e-03,\n",
       "        -2.84850951e-02, -3.43958288e-03, -4.01048884e-02,\n",
       "         3.36639993e-02, -2.80958898e-02, -4.96141315e-02,\n",
       "         2.89043672e-02, -4.98566516e-02,  3.99629027e-03,\n",
       "        -1.14523657e-02, -1.93347819e-02, -1.52365342e-02,\n",
       "        -9.76108387e-03, -3.80818620e-02, -3.68509181e-02,\n",
       "         4.00921963e-02,  2.48095505e-02,  2.90709846e-02,\n",
       "         3.18888687e-02, -4.81402539e-02, -1.39996633e-02,\n",
       "        -4.49224599e-02, -1.56582817e-02, -8.54701921e-03,\n",
       "        -4.72284220e-02,  4.66085337e-02, -2.80853044e-02,\n",
       "        -2.04641223e-02],\n",
       "       [-4.06603217e-02, -5.94556332e-04, -1.10758319e-02,\n",
       "        -1.90770626e-03, -1.62963644e-02,  1.23770237e-02,\n",
       "         6.22026995e-03, -4.80129234e-02,  2.68428661e-02,\n",
       "         2.61092223e-02, -3.83683071e-02, -2.13852171e-02,\n",
       "         4.24261726e-02, -3.09048779e-02,  1.74421407e-02,\n",
       "         9.51100141e-04, -3.80102023e-02, -2.57644188e-02,\n",
       "        -6.34543970e-03, -8.42609257e-03, -2.04716455e-02,\n",
       "         3.95911820e-02, -1.80042908e-03,  4.85761799e-02,\n",
       "        -4.50925343e-02, -3.56988795e-02, -3.44611183e-02,\n",
       "        -8.45074654e-03,  5.80269098e-03, -2.83414721e-02,\n",
       "        -3.86425741e-02,  1.22989416e-02, -1.38085969e-02,\n",
       "        -3.71865407e-02, -3.63188758e-02,  2.81275176e-02,\n",
       "        -1.97718982e-02, -4.43987958e-02, -4.57314253e-02,\n",
       "         1.50206946e-02, -1.25031546e-03, -3.25848907e-03,\n",
       "        -1.88235044e-02, -3.01554091e-02, -1.18078813e-02,\n",
       "        -5.66948205e-04, -4.78584543e-02, -1.42917745e-02,\n",
       "         3.87562402e-02, -1.15474239e-02,  4.28149365e-02,\n",
       "         1.50617212e-03, -6.60972670e-03, -4.47312258e-02,\n",
       "        -4.47320715e-02, -3.37646380e-02,  5.20864874e-03,\n",
       "        -8.31462443e-04,  1.56048685e-03,  2.24506594e-02,\n",
       "        -9.94986296e-03, -3.87319922e-02, -1.67931542e-02,\n",
       "         1.74312927e-02],\n",
       "       [ 1.55927278e-02, -3.67415659e-02, -7.38800690e-03,\n",
       "         5.27992100e-03,  1.68604963e-02, -3.72925773e-02,\n",
       "        -2.17676163e-03, -3.41465846e-02,  2.03008167e-02,\n",
       "        -1.86126344e-02,  4.02790196e-02, -1.86522231e-02,\n",
       "         2.70998478e-03,  1.41643547e-02, -3.58219370e-02,\n",
       "        -1.75194368e-02,  4.04107831e-02, -2.06394326e-02,\n",
       "         7.29813427e-03,  1.73084252e-02,  1.81957819e-02,\n",
       "         1.27650611e-02, -6.08264282e-03, -3.72713432e-02,\n",
       "        -2.85997149e-02, -4.56838012e-02,  4.47787978e-02,\n",
       "        -2.62547266e-02,  4.52942774e-03,  3.37326564e-02,\n",
       "         2.02792771e-02, -1.33628733e-02,  7.01941177e-03,\n",
       "         1.20130777e-02,  2.44954266e-02, -4.31288257e-02,\n",
       "        -3.88357528e-02, -4.19889092e-02,  2.42321007e-02,\n",
       "        -6.37763739e-03,  3.82416509e-02,  2.05538608e-02,\n",
       "        -4.21744958e-02,  4.86539043e-02,  3.08420770e-02,\n",
       "        -1.68163888e-02,  7.94161484e-03, -6.13998249e-03,\n",
       "        -4.87317555e-02,  2.72049941e-02, -1.23000853e-02,\n",
       "        -5.76883554e-03,  1.03906393e-02, -1.60744563e-02,\n",
       "         4.66100015e-02,  2.25065388e-02,  1.58987083e-02,\n",
       "         4.68637794e-03, -3.36161144e-02,  2.66179331e-02,\n",
       "         2.82282121e-02,  2.26074941e-02, -3.23778018e-02,\n",
       "        -5.92720509e-03],\n",
       "       [ 3.08157913e-02,  4.04708050e-02,  1.66125558e-02,\n",
       "        -9.23060253e-03, -3.66954803e-02, -1.86183341e-02,\n",
       "        -9.57674906e-03,  3.77604030e-02, -2.34439857e-02,\n",
       "        -3.93791422e-02,  1.75027922e-03, -5.73316962e-03,\n",
       "        -8.44611973e-03, -5.44130802e-04, -2.41189133e-02,\n",
       "         4.19653170e-02, -1.58151872e-02, -6.18769974e-03,\n",
       "        -2.40476970e-02,  4.22714241e-02,  2.78347023e-02,\n",
       "        -4.82258908e-02,  3.97094339e-03,  2.41218470e-02,\n",
       "        -4.06348482e-02,  7.98166916e-03, -3.63999009e-02,\n",
       "         3.38302366e-02, -4.82177027e-02, -3.11983116e-02,\n",
       "        -1.49820670e-02, -5.01918793e-03,  4.91865315e-02,\n",
       "        -1.87500250e-02,  9.08815861e-03, -8.75115395e-03,\n",
       "         3.91196497e-02,  4.05447818e-02, -3.78417484e-02,\n",
       "        -1.24607198e-02, -4.81093898e-02, -2.20876466e-02,\n",
       "         4.85877879e-02,  2.78191827e-02,  9.65775177e-03,\n",
       "         2.02801935e-02,  4.11306061e-02,  2.94279717e-02,\n",
       "         4.47172038e-02,  2.74363048e-02, -1.05656683e-04,\n",
       "        -2.06862763e-03,  2.30811723e-02, -4.04834151e-02,\n",
       "        -2.92583350e-02, -3.47678065e-02, -2.43414771e-02,\n",
       "         1.47700571e-02, -4.48565744e-02,  1.11170188e-02,\n",
       "        -2.84082778e-02, -4.13267612e-02,  1.36335008e-02,\n",
       "        -2.88964398e-02],\n",
       "       [ 3.86611931e-02,  3.69084999e-03,  4.93030436e-02,\n",
       "        -2.74225120e-02,  1.57522075e-02, -1.31458640e-02,\n",
       "        -3.59560028e-02,  4.65181507e-02, -2.47451067e-02,\n",
       "         1.02310292e-02, -1.83950737e-03,  4.45927717e-02,\n",
       "        -3.43037993e-02,  3.60709913e-02, -4.68103178e-02,\n",
       "        -3.77789252e-02,  3.38705517e-02, -4.36809547e-02,\n",
       "        -1.73444860e-02,  4.43689339e-02, -4.74282280e-02,\n",
       "         4.30170633e-02,  1.29204728e-02,  4.68168147e-02,\n",
       "        -1.92552805e-02,  2.33962387e-03, -1.11269467e-02,\n",
       "         2.88246609e-02, -2.94947866e-02,  3.48321684e-02,\n",
       "        -2.66817454e-02, -1.71467066e-02, -4.77740541e-02,\n",
       "        -2.30299234e-02, -4.33401018e-03, -4.24602628e-02,\n",
       "        -1.43303163e-02,  4.43807133e-02, -5.97859547e-03,\n",
       "        -4.24383543e-02,  4.44647111e-02, -4.39225212e-02,\n",
       "         3.02229784e-02, -6.41676039e-03, -6.19073957e-03,\n",
       "        -2.73056384e-02, -1.92888509e-02,  2.85424627e-02,\n",
       "        -3.14870700e-02, -9.30181891e-03,  1.47125237e-02,\n",
       "        -2.64217146e-02, -3.98921594e-02, -2.94854529e-02,\n",
       "        -3.02672274e-02,  2.50490792e-02, -2.98424121e-02,\n",
       "         4.97726314e-02, -4.00298014e-02, -4.88982201e-02,\n",
       "        -1.17212534e-02, -4.47012186e-02,  1.00584626e-02,\n",
       "         5.93554229e-04],\n",
       "       [ 1.49779655e-02, -1.51953809e-02, -1.90750118e-02,\n",
       "         1.96966864e-02,  4.61693667e-02,  2.63156779e-02,\n",
       "        -1.01801008e-03,  6.37935475e-03, -4.94587682e-02,\n",
       "        -4.26716730e-03, -2.21198201e-02,  4.65502776e-02,\n",
       "        -3.28569636e-02, -1.42663606e-02,  1.78743117e-02,\n",
       "        -2.72571202e-02,  4.90378402e-02,  4.36425321e-02,\n",
       "        -8.05636495e-03,  5.03502041e-03, -2.81605870e-03,\n",
       "         3.58327143e-02, -4.24207114e-02,  2.67105587e-02,\n",
       "         4.21729945e-02, -2.15468295e-02, -4.69981916e-02,\n",
       "        -4.40632962e-02, -4.25224900e-02, -5.43083996e-03,\n",
       "         2.86155455e-02,  1.04299299e-02,  2.12524645e-02,\n",
       "        -1.99356806e-02,  7.37986714e-03, -3.52760181e-02,\n",
       "         1.91376694e-02,  1.74647234e-02,  4.89085354e-02,\n",
       "         3.86994593e-02,  2.11439990e-02,  2.09441446e-02,\n",
       "         4.94086482e-02,  3.09990160e-02, -2.21449137e-02,\n",
       "         4.65999357e-02,  3.32800783e-02,  2.95245387e-02,\n",
       "         7.00789690e-03,  6.66879490e-03, -2.42967010e-02,\n",
       "         1.53963640e-03, -1.80789120e-02,  2.19098963e-02,\n",
       "         2.00661905e-02, -1.45971067e-02,  1.22813582e-02,\n",
       "        -3.74334455e-02, -2.33272444e-02,  3.11586298e-02,\n",
       "         3.05282958e-02,  1.91550367e-02,  2.30001323e-02,\n",
       "        -3.07661537e-02],\n",
       "       [ 3.08157913e-02,  4.04708050e-02,  1.66125558e-02,\n",
       "        -9.23060253e-03, -3.66954803e-02, -1.86183341e-02,\n",
       "        -9.57674906e-03,  3.77604030e-02, -2.34439857e-02,\n",
       "        -3.93791422e-02,  1.75027922e-03, -5.73316962e-03,\n",
       "        -8.44611973e-03, -5.44130802e-04, -2.41189133e-02,\n",
       "         4.19653170e-02, -1.58151872e-02, -6.18769974e-03,\n",
       "        -2.40476970e-02,  4.22714241e-02,  2.78347023e-02,\n",
       "        -4.82258908e-02,  3.97094339e-03,  2.41218470e-02,\n",
       "        -4.06348482e-02,  7.98166916e-03, -3.63999009e-02,\n",
       "         3.38302366e-02, -4.82177027e-02, -3.11983116e-02,\n",
       "        -1.49820670e-02, -5.01918793e-03,  4.91865315e-02,\n",
       "        -1.87500250e-02,  9.08815861e-03, -8.75115395e-03,\n",
       "         3.91196497e-02,  4.05447818e-02, -3.78417484e-02,\n",
       "        -1.24607198e-02, -4.81093898e-02, -2.20876466e-02,\n",
       "         4.85877879e-02,  2.78191827e-02,  9.65775177e-03,\n",
       "         2.02801935e-02,  4.11306061e-02,  2.94279717e-02,\n",
       "         4.47172038e-02,  2.74363048e-02, -1.05656683e-04,\n",
       "        -2.06862763e-03,  2.30811723e-02, -4.04834151e-02,\n",
       "        -2.92583350e-02, -3.47678065e-02, -2.43414771e-02,\n",
       "         1.47700571e-02, -4.48565744e-02,  1.11170188e-02,\n",
       "        -2.84082778e-02, -4.13267612e-02,  1.36335008e-02,\n",
       "        -2.88964398e-02],\n",
       "       [ 5.40808588e-03, -1.84619203e-02, -7.47836754e-03,\n",
       "         4.07899506e-02,  4.90709879e-02, -3.85174640e-02,\n",
       "         4.97957356e-02,  1.42244250e-03,  2.35365666e-02,\n",
       "         8.27836990e-03, -4.91913669e-02,  3.90828736e-02,\n",
       "         4.88963164e-02,  7.09577650e-03, -1.62356980e-02,\n",
       "         3.98482345e-02, -4.43774723e-02,  2.76302807e-02,\n",
       "        -3.65691409e-02,  2.42905654e-02,  1.35545768e-02,\n",
       "         1.76831596e-02,  1.56452097e-02, -7.23675638e-03,\n",
       "        -1.03021786e-03,  1.52125098e-02, -2.84429193e-02,\n",
       "         4.55197580e-02, -3.32658887e-02, -4.67080958e-02,\n",
       "        -1.61476508e-02,  2.00492628e-02,  3.29211093e-02,\n",
       "        -3.71790528e-02, -2.72740256e-02, -2.83809304e-02,\n",
       "        -1.53497569e-02, -2.97348574e-03, -2.84797680e-02,\n",
       "        -3.89603488e-02, -2.35791802e-02,  1.17957592e-02,\n",
       "         2.21826136e-04,  1.32300593e-02, -4.47198153e-02,\n",
       "        -1.21235140e-02, -1.17825270e-02,  1.42978765e-02,\n",
       "        -1.38562098e-02,  2.81475894e-02, -3.25396545e-02,\n",
       "         4.27917391e-03, -2.19336506e-02,  1.97848342e-02,\n",
       "        -4.25758213e-03, -2.19372660e-03,  2.07574107e-02,\n",
       "         2.24346407e-02,  4.56547402e-02,  4.97899689e-02,\n",
       "         4.06229757e-02, -1.44644976e-02, -4.99420241e-03,\n",
       "        -3.56886610e-02],\n",
       "       [-4.46997993e-02,  3.22444551e-02, -3.58901508e-02,\n",
       "        -1.86107308e-03, -3.81816253e-02, -3.67007405e-03,\n",
       "        -7.68718868e-03,  3.14802043e-02, -1.67419091e-02,\n",
       "        -1.92152988e-02, -4.08793576e-02,  4.58296277e-02,\n",
       "         2.15826295e-02,  2.51676552e-02,  3.05122845e-02,\n",
       "         3.38189043e-02,  3.97427790e-02,  2.24243067e-02,\n",
       "         4.77800854e-02,  3.88403982e-03, -1.29799843e-02,\n",
       "         3.93518843e-02, -4.45064902e-02, -2.98841950e-02,\n",
       "        -3.29037905e-02,  6.52300194e-03,  2.03910731e-02,\n",
       "         4.69949581e-02, -1.13083720e-02,  1.69269927e-02,\n",
       "        -3.70737202e-02, -3.12470682e-02, -2.63415929e-02,\n",
       "         2.41592042e-02, -2.08352562e-02, -1.35996342e-02,\n",
       "        -1.21967904e-02, -1.66400895e-02, -3.77812609e-02,\n",
       "        -2.03258637e-02, -4.17830124e-02,  1.48838274e-02,\n",
       "         4.69101705e-02, -2.09577568e-02,  3.15354206e-02,\n",
       "         3.85841466e-02, -4.28160690e-02, -4.34602611e-02,\n",
       "        -2.08880305e-02, -8.49997997e-03,  2.98656560e-02,\n",
       "        -3.30614932e-02, -2.84301117e-03,  8.35714489e-03,\n",
       "         2.53786482e-02,  1.11472830e-02, -9.21137258e-03,\n",
       "        -5.21421432e-03,  1.91377513e-02,  6.69180229e-03,\n",
       "         7.98724964e-03, -3.39374319e-02, -1.59338601e-02,\n",
       "        -2.62022018e-03]], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 建立模型\n",
    "model = tf.keras.Sequential()\n",
    "\n",
    "# 模型只含嵌入層(Embedding layer)\n",
    "# 字彙表最大為1000，輸出維度為 64，輸入的字數為 10\n",
    "model.add(layers.Embedding(input_dim=1000, output_dim=64))\n",
    "\n",
    "# 產生亂數資料，32筆資料，每筆 10 個數字\n",
    "input_array = np.random.randint(1000, size=(32, 10))\n",
    "\n",
    "# 指定優化器、損失函數\n",
    "model.compile('rmsprop', 'mse')\n",
    "\n",
    "# 預測\n",
    "output_array = model.predict(input_array)\n",
    "print(output_array.shape)\n",
    "output_array[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用真實的資料轉換"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 4)\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000021132B923A0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10, 4, 64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import one_hot\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# 測試資料\n",
    "docs = ['Well done!',\n",
    "        'Good work',\n",
    "        'Great effort',\n",
    "        'nice work',\n",
    "        'Excellent!',\n",
    "        'Weak',\n",
    "        'Poor effort!',\n",
    "        'not good',\n",
    "        'poor work',\n",
    "        'Could have done better.']\n",
    "\n",
    "# 轉成 one-hot encoding\n",
    "vocab_size = 50 # 字典最大字數\n",
    "maxlen = 4      # 語句最大字數\n",
    "encoded_docs = [one_hot(d, vocab_size) for d in docs]\n",
    "\n",
    "# 轉成固定長度，長度不足則後面補空白\n",
    "padded_docs = pad_sequences(encoded_docs, maxlen=maxlen, padding='post')\n",
    "\n",
    "# 模型只有 Embedding\n",
    "model = tf.keras.Sequential()\n",
    "model.add(layers.Embedding(vocab_size, 64, input_length=maxlen))\n",
    "model.compile('rmsprop', 'mse')\n",
    "\n",
    "# 預測\n",
    "output_array = model.predict(padded_docs)\n",
    "output_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[34, 33]\n",
      "(10, 4)\n"
     ]
    }
   ],
   "source": [
    "# one-hot encoding 轉換結果\n",
    "print(encoded_docs[0])\n",
    "\n",
    "# 補空白後的輸入維度\n",
    "print(padded_docs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加上完全連接層(Dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_8 (Embedding)      (None, 4, 8)              400       \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 433\n",
      "Trainable params: 433\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Accuracy: 89.999998\n"
     ]
    }
   ],
   "source": [
    "# 定義 10 個語句的正面(1)或負面(0)的情緒\n",
    "labels = np.array([1,1,1,1,1,0,0,0,0,0])\n",
    "\n",
    "vocab_size = 50\n",
    "maxlen = 4\n",
    "encoded_docs = [one_hot(d, vocab_size) for d in docs]\n",
    "padded_docs = pad_sequences(encoded_docs, maxlen=maxlen, padding='post')\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(layers.Embedding(vocab_size, 8, input_length=maxlen))\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "# 加上完全連接層(Dense)\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "# 指定優化器、損失函數\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "# 模型訓練\n",
    "model.fit(padded_docs, labels, epochs=50, verbose=0)\n",
    "\n",
    "# 模型評估\n",
    "loss, accuracy = model.evaluate(padded_docs, labels, verbose=0)\n",
    "print('Accuracy: %f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5838079 ],\n",
       "       [0.5428731 ],\n",
       "       [0.50959533],\n",
       "       [0.52323276],\n",
       "       [0.53539276],\n",
       "       [0.50386965],\n",
       "       [0.49095556],\n",
       "       [0.49666357],\n",
       "       [0.5119646 ],\n",
       "       [0.41784462]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(padded_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加上 RNN 神經層"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_10 (Embedding)     (None, 4, 8)              400       \n",
      "_________________________________________________________________\n",
      "simple_rnn_2 (SimpleRNN)     (None, 128)               17536     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 18,065\n",
      "Trainable params: 18,065\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Accuracy: 100.000000\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(layers.Embedding(vocab_size, 8, input_length=maxlen))\n",
    "\n",
    "# 加上 RNN 神經層，輸出 128 個神經元\n",
    "model.add(layers.SimpleRNN(128))\n",
    "\n",
    "# 加上完全連接層(Dense)\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "# 指定優化器、損失函數\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())\n",
    "# 模型訓練\n",
    "model.fit(padded_docs, labels, epochs=50, verbose=0)\n",
    "\n",
    "# 模型評估\n",
    "loss, accuracy = model.evaluate(padded_docs, labels, verbose=0)\n",
    "print('Accuracy: %f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:8 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000021139CDE9D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[9.9992478e-01],\n",
       "       [9.9990129e-01],\n",
       "       [9.9997473e-01],\n",
       "       [9.9999011e-01],\n",
       "       [9.9997044e-01],\n",
       "       [2.6669091e-05],\n",
       "       [4.1497133e-05],\n",
       "       [7.0826311e-05],\n",
       "       [7.6519085e-05],\n",
       "       [1.3496495e-05]], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(padded_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 1, 1, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.predict_classes(padded_docs).reshape(-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用詞向量(Word2Vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 讀取 GloVe 300維的詞向量，產生字典資料型變數，方便搜尋"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the whole embedding into memory\n",
    "embeddings_index = dict()\n",
    "f = open('./GloVe/glove.6B.300d.txt', encoding='utf8')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.array(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 分詞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 6,  2,  0,  0],\n",
       "       [ 3,  1,  0,  0],\n",
       "       [ 7,  4,  0,  0],\n",
       "       [ 8,  1,  0,  0],\n",
       "       [ 9,  0,  0,  0],\n",
       "       [10,  0,  0,  0],\n",
       "       [ 5,  4,  0,  0],\n",
       "       [11,  3,  0,  0],\n",
       "       [ 5,  1,  0,  0],\n",
       "       [12, 13,  2, 14]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 分詞\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "t = Tokenizer()\n",
    "t.fit_on_texts(docs)\n",
    "\n",
    "vocab_size = len(t.word_index) + 1\n",
    "\n",
    "# 轉為序列整數\n",
    "encoded_docs = t.texts_to_sequences(docs)\n",
    "\n",
    "# 補 0\n",
    "padded_docs = pad_sequences(encoded_docs, maxlen=maxlen, padding='post')\n",
    "padded_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 轉換為GloVe 300維的詞向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.19205999,  0.16459   ,  0.060122  ,  0.17696001, -0.27405   ,\n",
       "        0.079646  , -0.25292999, -0.11763   ,  0.17614   , -1.97870004,\n",
       "        0.10707   , -0.028088  ,  0.093991  ,  0.48135   , -0.037581  ,\n",
       "        0.0059231 , -0.11118   , -0.099847  , -0.22189   ,  0.0062044 ,\n",
       "        0.17721   ,  0.25786   ,  0.42120999, -0.13085   , -0.32839   ,\n",
       "        0.39208999, -0.050214  , -0.46766999, -0.063107  , -0.0023065 ,\n",
       "        0.21005   ,  0.26982   , -0.22652   , -0.42958999, -0.89682001,\n",
       "        0.21932   , -0.0020377 ,  0.1358    , -0.12661999, -0.058927  ,\n",
       "        0.0049502 , -0.28457999, -0.29530999, -0.29295999, -0.24212   ,\n",
       "        0.091915  ,  0.01977   ,  0.14503001,  0.26495999,  0.10817   ,\n",
       "        0.029115  ,  0.075254  ,  0.16463999,  0.12097   , -0.37494001,\n",
       "        0.52671999,  0.094318  , -0.054813  , -0.021008  ,  0.081353  ,\n",
       "        0.18735   , -0.14458001, -0.031203  ,  0.31753999,  0.027703  ,\n",
       "       -0.28657001,  0.34630999, -0.27772   ,  0.18669   , -0.11684   ,\n",
       "        0.21551999, -0.21927001,  0.19778   ,  0.68763   , -0.076211  ,\n",
       "       -0.06296   ,  0.13236   ,  0.55324   ,  0.15331   , -0.17332999,\n",
       "       -0.35551   ,  0.16426   ,  0.34196001, -0.13568   ,  0.071228  ,\n",
       "        0.49147001, -0.45590001,  0.28874999, -0.14091   , -0.025825  ,\n",
       "       -0.55035001,  0.4946    , -0.2378    , -0.10571   ,  0.06842   ,\n",
       "       -0.32091999, -0.39829001, -0.22886001,  0.23120999, -0.17178001,\n",
       "        0.13185   , -0.096899  , -0.23882   , -0.46972001,  0.009816  ,\n",
       "        0.22386999,  0.10266   ,  0.19253001,  0.076285  ,  0.047143  ,\n",
       "       -0.057814  , -0.39348   , -0.39149001, -0.45412001, -0.17676   ,\n",
       "        0.055638  , -0.18709999, -0.18489   , -0.41837001, -0.14267001,\n",
       "       -0.10478   ,  0.13553999,  0.035178  , -0.060326  ,  0.16064   ,\n",
       "        0.011063  , -0.16869999,  0.36743   , -0.18429001,  0.29710999,\n",
       "        0.28083   , -0.10677   ,  0.39662999,  0.24402   , -0.43074   ,\n",
       "        0.01706   , -0.41753   ,  0.065152  ,  0.0037614 ,  0.10838   ,\n",
       "       -0.21235999,  0.33851001,  0.10936   ,  0.095847  , -0.19022   ,\n",
       "       -0.24674   ,  0.19497   ,  0.22927   ,  0.071891  ,  0.0079942 ,\n",
       "       -0.37593001, -0.11312   ,  0.043079  , -0.34375   ,  0.10823   ,\n",
       "        0.02953   ,  0.011398  ,  0.093628  ,  0.048618  , -0.0046744 ,\n",
       "        0.016682  , -0.30241999, -0.28097001, -0.0022392 ,  0.031192  ,\n",
       "        0.28744999,  0.1646    ,  0.031733  ,  0.26883999,  0.17507   ,\n",
       "        0.023629  , -0.31182   , -0.51556998, -0.53126001,  0.15457   ,\n",
       "        0.34608001, -0.39877   ,  0.010599  ,  0.122     , -0.049123  ,\n",
       "        0.008877  ,  0.036539  ,  0.25753   , -0.13761   , -0.28007001,\n",
       "       -0.050031  ,  0.013727  , -0.051568  , -0.14297999, -0.090281  ,\n",
       "       -0.24719   ,  0.10075   ,  0.37577   ,  0.088239  ,  0.055098  ,\n",
       "       -0.18378   ,  0.21780001,  0.45194   , -0.080527  , -0.89216   ,\n",
       "        0.78140002,  0.0058011 , -0.08096   ,  0.28264999,  0.23353   ,\n",
       "        0.19334   ,  0.11915   ,  0.021924  , -0.066155  , -0.53166997,\n",
       "       -0.036124  ,  0.22792   , -0.10224   , -0.11242   ,  0.20747   ,\n",
       "        0.047715  ,  0.025303  ,  0.16956   , -0.17952   ,  0.074963  ,\n",
       "       -0.15693   , -0.019777  , -0.49594   , -0.18127   ,  0.22142   ,\n",
       "       -0.36939001, -0.02147   , -0.075791  ,  0.1063    , -0.18601   ,\n",
       "        0.21159001,  0.13786   ,  0.14431   , -0.49601999, -0.28496999,\n",
       "       -0.34603   ,  0.19776   ,  0.069136  , -0.074623  , -0.17207   ,\n",
       "       -0.13899   ,  0.30406001,  0.1962    ,  0.22842   , -0.58197999,\n",
       "        0.010421  , -0.049684  ,  0.38183001,  0.064393  , -0.062792  ,\n",
       "        0.29249001, -0.2538    , -0.20906   ,  0.23159   ,  0.56015003,\n",
       "       -0.083504  ,  0.12453   ,  0.056502  ,  0.15719   , -0.09632   ,\n",
       "       -0.026005  ,  0.47233   , -0.38429001,  0.31663001,  0.031454  ,\n",
       "        0.49827999, -0.20428   , -0.050342  , -0.03607   , -0.13361999,\n",
       "        0.13428999, -0.10579   ,  0.15412   ,  0.15767001,  0.043169  ,\n",
       "        0.22847   , -1.99090004, -0.29824001,  0.22634   ,  0.04847   ,\n",
       "       -0.19123   , -0.18863   ,  0.13316   ,  0.19259   ,  0.093213  ,\n",
       "        0.16545001,  0.089307  ,  0.065742  , -0.28632   , -0.35547999,\n",
       "        0.10424   , -0.27811   , -0.050585  ,  0.15038   , -0.088717  ,\n",
       "       -0.26166999, -0.028425  , -0.34661001, -0.0097282 ,  0.095883  ])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 轉換為 GloVe 300維的詞向量\n",
    "# 初始化輸出\n",
    "embedding_matrix = np.zeros((vocab_size, 300))\n",
    "\n",
    "# 讀取詞向量值\n",
    "for word, i in t.word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "\n",
    "# 任取一筆觀察        \n",
    "embedding_matrix[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding 設為不需訓練，直接輸入轉換後的向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_13 (Embedding)     (None, 4, 300)            4500      \n",
      "_________________________________________________________________\n",
      "simple_rnn_5 (SimpleRNN)     (None, 128)               54912     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 59,541\n",
      "Trainable params: 55,041\n",
      "Non-trainable params: 4,500\n",
      "_________________________________________________________________\n",
      "None\n",
      "WARNING:tensorflow:7 out of the last 7 calls to <function Model.make_test_function.<locals>.test_function at 0x000002116DD353A0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Accuracy: 100.000000\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "\n",
    "# trainable=False：不需訓練，直接輸入轉換後的向量\n",
    "model.add(layers.Embedding(vocab_size, 300, weights=[embedding_matrix], \n",
    "                           input_length=maxlen, trainable=False))\n",
    "model.add(layers.SimpleRNN(128))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "# 指定優化器、損失函數\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "# 模型訓練\n",
    "model.fit(padded_docs, labels, epochs=50, verbose=0)\n",
    "\n",
    "# 模型評估\n",
    "loss, accuracy = model.evaluate(padded_docs, labels, verbose=0)\n",
    "print('Accuracy: %f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 1, 1, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.predict_classes(padded_docs).reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:9 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002116DC66D30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[9.9977702e-01],\n",
       "       [9.9972540e-01],\n",
       "       [9.9990332e-01],\n",
       "       [9.9989653e-01],\n",
       "       [9.9989903e-01],\n",
       "       [1.1761398e-04],\n",
       "       [1.1944198e-04],\n",
       "       [2.3762533e-04],\n",
       "       [1.7523505e-04],\n",
       "       [1.6099006e-04]], dtype=float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(padded_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
